---
title: "Tema 6"
author: "Daniel Jaffet León Chávez"
date: "17/10/2020"
output: pdf_document
---
```{r, echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
```

```{r setup,include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## 1)       Los datos de la siguiente tabla pertenecen a la pérdida en toneladas por Ha de patatas después de ser atacadas por un microorganismo y ser combatido éste a su vez por un plaguicida. Queremos analizar si existen diferencias significativas en menores toneladas de producción de pérdidas, mediante un Análisis de Varianza. Las hectáreas fueron dispuestas al azar así como los plaguicidas:

```{r, echo=FALSE}

matrix(c(50,52,54,53,51,65,66,69,64,68,30,32,34,33,31), byrow = T, ncol = 5)

```


## a) ¿Cuáles son nuestras hipótesis a contrastar?

h0 = Hay igualdades significativas en menores toneladas de producción de pérdidas

h1 = Hay diferencias significativas en menores toneladas de producción de pérdidas

```{r, include=FALSE}
library(WRS)
```


```{r}

x = c(50,52,54,53,51,65,66,69,64,68,30,32,34,33,31)
x= unlist(x)
plag = factor(rep(c('plag_1','plag_2','plag_3'), c(5,5,5)))
datitos = data.frame(x1= c(50,52,54,53,51), x2= c(65,66,69,64,68), x3= c(30,32,34,33,31))

data_plag = data.frame(plag, x= unlist(x))

summary(aov(x~plag, data = data_plag))

resultados = aov(x~plag, data = data_plag)

TukeyHSD(resultados)
```


## b) ¿Qué nos dicen los resultados del Anova?

Como el P-valor es más elevado que 0.05, entonces se podría concluir que no hay diferencia entre los grupos, y además, el test TukeyHSD revela que los 3 grupos son homogeneos entre sí, ya que los 3 grupos de valores estan entre -0.3 y 0.5 (contienen al 0).

# 2)       Haga los Análisis de Supuestos o Condiciones de la Tabla del ejercicio anterior de Anova que usted considere.

Hagamos un boxplot:

```{r}

boxplot(datitos)

```

Ahota apliquemos el test de Barlett y el OneWayTest:

```{r, include=T}

bartlett.test(datitos)

oneway.test(x~plag, data = data_plag)


```
El One-Way-Test no asume igualdad de varianzas, por lo tanto, vamos a aplicar pruebas avanzadas, pero primero, vamos a realizar los respectivos análisis de normalidad:

```{r, getwd()}

X = c(50,52,54,53,51,65,66,69,64,68,30,32,34,33,31)
x= unlist(x)

par(mfrow = c(1,3))
qqnorm(x[1:5], pch=14)
qqnorm(x[6:10], pch=14)
qqnorm(x[11:15], pch=14)

```
El qq plot de los datos que van desde el dato 6 al 10 de la producción muestran un comportamiento que no es normal, se podría desestimar la homogeneidad de grupo, a menos que se aplique la prueba avanzada de Welch y Box:

```{r}
datitos = data.frame(x1= c(50,52,54,53,51), x2= c(65,66,69,64,68), x3= c(30,32,34,33,31))

t1way(datitos, 0.1)

```

Ahora nos aseguramos con la prueba Generalización Robusta del Test de Box:

```{r, echo=F}

box1way(datitos, 0.1)

```


Como el valor de significancia tiende a 0, ahora si se puede asegurar que las muestras difieren entre si, y rechazamos la hipótesis nula y aceptamos la hipótesis alternativa. Apliquemos el test de lincon:

```{r}
lincon(datitos,tr=0.2,alpha=0.05)
```
Como el valor de cada grupo de test es mayor que la de crit, se puede concluir que hay diferencias entre cada muestra.




# 3)      Se quiere estudiar si el nivel de ataque de un organismo de la patata depende del mes, de diciembre a febrero, que es cuando se conoce se da el ataque. Por otro lado se tienen dos plaguicidas de los que se quiere comprobar si combaten el ataque de tal microorganismo. Y ello se comprueba en una muestra al azar de 24 parcelas. Los resultados en gravedad del ataque en una escala de 0 a 60 los tenemos en la siguiente tabla:

## Calcule el Anova de dos factores, la homogeneidad de varianzas, las medias marginales y medias por condición. 

```{r, include=F}

# Como cuadros de datos normales

tr1 = data.frame(december=c(19,24,28,14), january = c(14,12,17,6), february = c(23,30,26,12))

tr2 = data.frame(december=c(50,52,48,51), january = c(43,45,42,42), february = c(48,50,51,53))

trt = data.frame(tr1, tr2)

```
```{r, include=F}

# Como factores

xx1= c(19,24,28,14,14,12,17,6,23,30,26,12,50,52,48,51,43,45,42,42,48,50,51,53)
mes= factor(rep(c("december", "january", "february"), c(8,8,8)))
tratamiento= factor(rep(c("tr1","tr2"), c(4,4)))

data_factor = data.frame(xx1, mes, tratamiento)

data_factor

```


```{r include=FALSE}
library(knitr)
```

```{r, echo=F}

kable(tr1, caption = "Tratamiento 1")
kable(tr2, caption = "Tratamiento 2")


```

Hagamos un boxplot y un qqplot
```{r}
boxplot(trt)
```

como se puede apreciar, aparentemente existe heterocedasticidad

```{r, echo=F}

xx1= c(19,24,28,14,14,12,17,6,23,30,26,12,50,52,48,51,43,45,42,42,48,50,51,53)

par(mfrow = c(2,3))
qqnorm(xx1[1:4], pch=14)
qqnorm(xx1[5:8], pch=14)
qqnorm(xx1[9:12], pch=14)
qqnorm(xx1[13:16], pch=14)
qqnorm(xx1[17:20], pch=14)
qqnorm(xx1[21:24], pch=14)

```

Para la serie de datos de enero del segundo grupo de estudio, se puede apreciar que no tiene un comportamiento normal. Apliquemos el test de Levene

```{r, include=T}
library(car)
leveneTest(data_factor$xx1 ~ data_factor$mes*data_factor$tratamiento)

```
El test de Levene indica que las varianzas se comportan de forma similar, por lo tanto podemos emplear una prueba ANOVA clásica:

```{r, include=T}
aov(data_factor$xx1 ~ data_factor$mes*data_factor$tratamiento, data = data_factor)
summary(aov(data_factor$xx1 ~ data_factor$mes*data_factor$tratamiento, data = data_factor))

```
Del resultado de la prueba ANOVA clásica, se puede observar que entre mes y tratamiento no hay interacción alguna pues los p valores son inferiores a 0.05. Hagamos un interaction plot

```{r, include=T}

interaction.plot(data_factor$mes, data_factor$tratamiento, data_factor$xx1)
interaction.plot(data_factor$tratamiento, data_factor$mes, data_factor$xx1)

```

La primera gráfica de interacción revela que hay una interacción entre el tratamiento 1 y el 2 entre diciembre y febrero, mientras que la segunda revela que no hay interacción alguna. Hagamos una prueba avanzada para corroborar lo que observamos con las pruebas clásicas:

```{r, include=T}

x1 = c(19,24,28,14)
x2 = c(14,12,17,6)
x3 = c(23,30,26,12)
x4 = c(50,52,48,51)
x5 = c(43,45,42,42)
x6 = c(48,50,51,53)

xmaster = list(x1,x2,x3,x4,x5,x6)

t2way(3,2,xmaster,tr=0.1)

```
Se puede notar que los 3 p-valores son menores a 0.05, por lo tanto se acepta la hipotesis alternativa pues si hay cambios entre mes y tratamiento. Hagamos Lincon

```{r,include=T}

lincon(xmaster, tr=0.2)

```
Ahora bien, como en la mayoria de los valores de crit son inferiores que los de test, y solo unos pocosen cada grupo son superiores de crit con respecto de la matriz $test, realmente hay pocos grupos homogoneosy la mayoría son distintos entre sí.


# Notas personales

## ANOVA es una prueba parametrica que debe cumplir 3 supuestos:

### a) Homocedasticidad: para eso se usa la prueba de Barlett o la prueba de levene
### b) Normalidad
### c) Independencia entre variables

### Ahora bien, para comprobar los resultados del ANOVA hay que hacer una prueba llamada TukeyHSD.

### la función unstack permite crear data frames a partir de variables categoricas (que no han sido transformadas a factor)

### El coeficiente de correlación por excelencia para datos normales es Pearson, pero cuando los datos son anormales se usa Spearman
